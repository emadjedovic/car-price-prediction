{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of links to 51 OLX pages containing cars:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_urls():\n",
    "    price_lo = 0\n",
    "    page_urls = []\n",
    "    for price_lo in range(1, 59000, 1000):\n",
    "        for page in range(1, 51):\n",
    "            page_urls.append(f\"https://olx.ba/pretraga?attr=&attr_encoded=1&category_id=18&page={page}&price_to={price_lo + 1000}&price_from={price_lo}\")\n",
    "        for page in range(1, 51):\n",
    "             page_urls.append(f\"https://olx.ba/pretraga?attr=&attr_encoded=1&category_id=18&page={page}&price_from=59000\")\n",
    "    return page_urls\n",
    "\n",
    "page_urls = get_page_urls()\n",
    "print(page_urls[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of pages containing car articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(page_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEB SCRAPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Boilerplate\n",
    "firefox_options = webdriver.FirefoxOptions()\n",
    "firefox_options.add_argument(\"--headless\") \n",
    "driver = webdriver.Firefox(options=firefox_options)\n",
    "\n",
    "# Define the batch number for processing links\n",
    "batch_num = 2\n",
    "\n",
    "# Define the file path to save urls to each car-article\n",
    "article_urls_file_path = 'article_urls.txt'\n",
    "\n",
    "# Iterate over each link and extract data\n",
    "for page_url in tqdm(page_urls[100*(batch_num - 1):100*batch_num], total=len(page_urls[100*(batch_num - 1):100*batch_num])):\n",
    "    page_url = page_url.strip()  # Remove any leading/trailing whitespace\n",
    "    if not page_url:\n",
    "        continue  # Skip empty lines\n",
    "\n",
    "    try:\n",
    "        # Open the URL\n",
    "        driver.get(page_url)\n",
    "        \n",
    "        # Wait for the page to fully load\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        # Give some extra time for JavaScript to execute\n",
    "        time.sleep(2)\n",
    "\n",
    "        a_tags = driver.find_elements(By.XPATH, \"//a[contains(@href, '/artikal/')]\")\n",
    "\n",
    "        # Extract the href attribute and store in a list\n",
    "        href_urls = [a_tag.get_attribute('href') for a_tag in a_tags]\n",
    "        with open(article_urls_file_path, 'a') as file:\n",
    "            for temp in href_urls:\n",
    "                file.write(temp + \"\\n\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve {page_url}: {e}\")\n",
    "\n",
    "# Quit the WebDriver session\n",
    "driver.quit()\n",
    "\n",
    "print(\"Finished processing all links.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING A CSV FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Boilerplate\n",
    "firefox_options = webdriver.FirefoxOptions()\n",
    "firefox_options.add_argument(\"--headless\")\n",
    "driver = webdriver.Firefox(options=firefox_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the input file path (of car articles):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = \"article_urls.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the output CSV file path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = 'car_data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the input file and read all lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(input_file_path, 'r') as file:\n",
    "    urls = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define headers for the CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\"URL\", \"Price\", \"Transmission\", \"Year\", \"Motor Strength (KW)\", \"Mileage\", \"Engine Capacity\", \"Manufacturer\", \"Model\", \"Fuel Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPORTING CAR DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code collects data from a list of URLs and writes it to a CSV file. It opens the file in append mode and sets up a CSV writer. For each URL, it uses a WebDriver to load the page and waits for it to fully render. It then extracts specific information, such as price, transmission, year, and other details, using selectors. If any information is missing, it assigns \"N/A\" and may skip writing that row if critical data is missing. Extracted data is written to the CSV file row by row. If an error occurs while processing a URL, it prints an error message. After processing all URLs, the WebDriver session is closed, and a completion message is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file_path, 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    # Create a CSV writer object\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    \n",
    "    # Write the headers to the CSV file\n",
    "    csvwriter.writerow(headers)\n",
    "\n",
    "    # Iterate over each link and extract data\n",
    "    for url in tqdm(urls, total=len(urls)):\n",
    "        url = url.strip()  # Remove any leading/trailing whitespace\n",
    "        if not url:\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        try:\n",
    "            # Open the URL\n",
    "            driver.get(url)\n",
    "            \n",
    "            # Wait for the page to fully load\n",
    "            WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "            \n",
    "            # Give some extra time for JavaScript to execute (adjust if necessary)\n",
    "            time.sleep(2)\n",
    "\n",
    "            # Extract the required information\n",
    "            try:\n",
    "                # Extract Price\n",
    "                price_element = driver.find_element(By.CSS_SELECTOR, \"span.price-heading.vat\")\n",
    "                price = price_element.text\n",
    "            except:\n",
    "                price = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                # Extract Transmission\n",
    "                transmission_element = driver.find_element(By.XPATH, \"//td[text()='Transmisija']/following-sibling::td\")\n",
    "                transmission = transmission_element.text.strip()\n",
    "            except:\n",
    "                transmission = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                # Extract Year\n",
    "                year_element = driver.find_element(By.XPATH, \"//td[text()='Godište']/following-sibling::td\")\n",
    "                year = year_element.text.strip()\n",
    "            except:\n",
    "                year = \"N/A\"\n",
    "            \n",
    "            try:\n",
    "                # Extract Motor Strength\n",
    "                motor_strength_element = driver.find_element(By.XPATH, \"//td[text()='Snaga motora (KW)']/following-sibling::td\")\n",
    "                motor_strength = motor_strength_element.text.strip()\n",
    "            except:\n",
    "                motor_strength = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                # Extract Mileage\n",
    "                mileage_element = driver.find_element(By.XPATH, \"//td[text()='Kilometraža']/following-sibling::td\")\n",
    "                mileage = mileage_element.text.strip()\n",
    "            except:\n",
    "                mileage = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                # Extract Engine Capacity\n",
    "                engine_capacity_element = driver.find_element(By.XPATH, \"//td[text()='Kubikaža']/following-sibling::td\")\n",
    "                engine_capacity = engine_capacity_element.text.strip()\n",
    "            except:\n",
    "                engine_capacity = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                # Extract Manufacturer\n",
    "                manufacturer_element = driver.find_element(By.XPATH, \"//td[text()='Proizvođač']/following-sibling::td/a\")\n",
    "                manufacturer = manufacturer_element.text.strip()\n",
    "            except:\n",
    "                manufacturer = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                # Extract Model\n",
    "                model_element = driver.find_element(By.XPATH, \"//td[text()='Model']/following-sibling::td/a\")\n",
    "                model = model_element.text.strip()\n",
    "            except:\n",
    "                model = \"N/A\"\n",
    "\n",
    "            try:\n",
    "                # Extract Fuel Type\n",
    "                fuel_type_element = driver.find_element(By.XPATH, \"//td[text()='Gorivo']/following-sibling::td\")\n",
    "                fuel_type = fuel_type_element.text.strip()\n",
    "            except:\n",
    "                fuel_type = \"N/A\"\n",
    "\n",
    "            if fuel_type == \"N/A\" or model == \"N/A\" or manufacturer == \"N/A\" or price == \"N/A\" or transmission == \"N/A\" or year == \"N/A\" or motor_strength == \"N/A\" or mileage == \"N/A\" or engine_capacity == \"N/A\":\n",
    "                continue\n",
    "            \n",
    "            # Write the extracted information to the CSV file\n",
    "            row = [url, price, transmission, year, motor_strength, mileage, engine_capacity, manufacturer, model, fuel_type]\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to retrieve {url}: {e}\")\n",
    "\n",
    "# Quit the WebDriver session\n",
    "driver.quit()\n",
    "\n",
    "print(\"Finished processing all links.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
